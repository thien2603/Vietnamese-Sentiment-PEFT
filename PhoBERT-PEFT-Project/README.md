# Ph√¢n t√≠ch So s√°nh Full Fine-Tuning v√† LoRA (PEFT) cho PhoBERT

ƒê√¢y l√† project nghi√™n c·ª©u so s√°nh hi·ªáu su·∫•t v√† hi·ªáu qu·∫£ c·ªßa b·ªën ph∆∞∆°ng ph√°p fine-tuning m√¥ h√¨nh `vinai/phobert-base` tr√™n b√†i to√°n Ph√¢n lo·∫°i C·∫£m x√∫c Ti·∫øng Vi·ªát (b·ªô d·ªØ li·ªáu 3 nh√£n: NEG, NEU, POS).

## 1. M·ª•c ti√™u Project

Nghi√™n c·ª©u n√†y th·ª±c hi·ªán m·ªôt chu·ªói th√≠ nghi·ªám c√≥ h·ªá th·ªëng ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi:
* **Hi·ªáu qu·∫£ (Efficiency):** K·ªπ thu·∫≠t LoRA (PEFT) gi√∫p ti·∫øt ki·ªám t√†i nguy√™n (s·ªë tham s·ªë, th·ªùi gian hu·∫•n luy·ªán) ƒë·∫øn m·ª©c n√†o so v·ªõi Full Fine-Tuning?
* **Hi·ªáu su·∫•t (Performance):** Ch√∫ng ta c√≥ ph·∫£i hy sinh ƒë·ªô ch√≠nh x√°c (F1-score) ƒë·ªÉ ƒë·ªïi l·∫•y hi·ªáu qu·∫£ kh√¥ng?
* **ƒêi·ªÉm t·ªëi ∆∞u (Sweet Spot):** Rank (r) c·ªßa LoRA b·∫±ng bao nhi√™u (`r=8, 16, hay 32`) l√† t·ªëi ∆∞u nh·∫•t cho b√†i to√°n n√†y?

## 2. K·∫øt qu·∫£ So s√°nh üìä

ƒê√¢y l√† b·∫£ng k·∫øt qu·∫£ cu·ªëi c√πng, ƒë∆∞·ª£c t·ªïng h·ª£p t·ª´ 4 l·∫ßn ch·∫°y th√≠ nghi·ªám.

| Ph∆∞∆°ng ph√°p | Test F1-macro | Th·ªùi gian train (s) | S·ªë tham s·ªë train | T·ªâ l·ªá tham s·ªë |
|:---|---:|---:|:---|---:|
| 1. Full Fine-Tuning (Baseline) | 0.7124 | 479.52 | 135,000,579 | 100.00% |
| 2. LoRA (PEFT) r=8 | 0.6571 | **70.50** | 1,035,267 | **0.77%** |
| 3. LoRA (PEFT) r=16 | **0.7127** | 104.58 | 14,748,675 | 10.92% |
| 4. LoRA (PEFT) r=32 | 0.7064 | 133.33 | 28,904,451 | 21.41% |

*(L∆∞u √Ω: ƒê√¢y l√† k·∫øt qu·∫£ t·ª´ output c·ªßa b·∫°n. LoRA r=16 l√† t·ªët nh·∫•t)*

## 3. Ph√¢n t√≠ch & K·∫øt lu·∫≠n

* **LoRA r=8:** Nhanh nh·∫•t (nhanh h∆°n 6.8 l·∫ßn) v√† nh·∫π nh·∫•t (0.77% params) nh∆∞ng hi·ªáu su·∫•t **th·∫•p** (F1=0.657), b·ªã underfit.
* **LoRA r=16 (ƒêi·ªÉm ng·ªçt üèÜ):** ƒê·∫°t F1-score **t∆∞∆°ng ƒë∆∞∆°ng** (th·∫≠m ch√≠ nh·ªânh h∆°n) Baseline, trong khi hu·∫•n luy·ªán **nhanh h∆°n 4.6 l·∫ßn** v√† ch·ªâ d√πng **10.9%** s·ªë tham s·ªë.
* **LoRA r=32:** Hi·ªáu su·∫•t gi·∫£m nh·∫π (c√≥ th·ªÉ do overfitting), ch·∫≠m h∆°n v√† t·ªën nhi·ªÅu tham s·ªë h∆°n `r=16`.

**K·∫øt lu·∫≠n:** Th√≠ nghi·ªám ch·ª©ng minh **LoRA (r=16)** l√† chi·∫øn l∆∞·ª£c t·ªëi ∆∞u, c√¢n b·∫±ng ho√†n h·∫£o gi·ªØa hi·ªáu su·∫•t v√† hi·ªáu qu·∫£ cho b√†i to√°n n√†y.

## 4. C√°ch ch·∫°y l·∫°i
1. C√†i ƒë·∫∑t th∆∞ vi·ªán: `pip install -r requirements.txt`
2. Ch·∫°y baseline: `python train.py --output_dir "results/baseline"`
3. Ch·∫°y LoRA r=16: `python train.py --output_dir "results/lora_r16" --use_lora --lora_rank 16`